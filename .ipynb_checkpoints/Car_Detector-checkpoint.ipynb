{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import glob\n",
    "import cv2\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import cm\n",
    "from moviepy.editor import VideoFileClip\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from skimage.feature import hog\n",
    "from scipy.ndimage.measurements import label\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = np.array([plt.imread(i) for i in glob.glob('./test_images/*.jpg')])\n",
    "\n",
    "car_images = []\n",
    "non_car_images = []\n",
    "\n",
    "for root, dirs, files in os.walk('./dataset/vehicles/'):\n",
    "    for file in files:\n",
    "        if file.endswith('.png'):\n",
    "            car_images.append(os.path.join(root, file))\n",
    "            \n",
    "for root, dirs, files in os.walk('./dataset/non-vehicles/'):\n",
    "    for file in files:\n",
    "        if file.endswith('.png'):\n",
    "            non_car_images.append(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Summary of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_car_images = len(car_images)\n",
    "n_non_car_images = len(non_car_images)\n",
    "img_shape = mpimg.imread(car_images[0]).shape\n",
    "print('No. of car images: ', n_car_images)\n",
    "print('No of non-car images: ', n_non_car_images)\n",
    "print('Image shape: ', img_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Car Image Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4,8, figsize=(16, 8))\n",
    "fig.subplots_adjust(hspace = 0, wspace=.1)\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i in np.arange(32):\n",
    "    img = cv2.imread(car_images[np.random.randint(0,n_car_images)])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    axs[i].axis('off')\n",
    "    axs[i].imshow(img)\n",
    "plt.savefig('output_images/car_samples.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-car Image Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4,8, figsize=(16, 8))\n",
    "fig.subplots_adjust(hspace = 0, wspace=.1)\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i in np.arange(32):\n",
    "    img = cv2.imread(non_car_images[np.random.randint(0,n_non_car_images)])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    axs[i].axis('off')\n",
    "    axs[i].imshow(img)\n",
    "plt.savefig('output_images/non_car_samples.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute binned color features by scaling images down \n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    # Use cv2.resize().ravel() to create the feature vector and flatten the vector in one row\n",
    "    features = cv2.resize(img, size).ravel() \n",
    "    # Return the feature vector\n",
    "    return features\n",
    "\n",
    "# Compute color histogram features  \n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the color channels separately,bins is the number of equally divided sectors in width\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n",
    "# Return HOG features and visualization\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    #The orientations are the number of buckets we want to create. Since I want to have a 9 x 1 matrix, I will set the orientations to 9\n",
    "    #pixels_per_cell defines the size of the cell for which we create the histograms.\n",
    "    #cells_per_block which is the size of the block over which we normalize the histogram. Here, we mention the cells per blocks and not the number of pixels. \n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True, \n",
    "                                  visualize=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True, \n",
    "                       visualize=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "\n",
    "# Extract feature wrapper that extracts and combines all features\n",
    "def extract_features(imgs, cspace='RGB', orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0, spatial_size=(32, 32),\n",
    "                        hist_bins=32, hist_range=(0, 256)):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        # Read in each one by one\n",
    "        image = mpimg.imread(file)\n",
    "        # apply color conversion if other than 'RGB' \n",
    "            \n",
    "        if cspace != 'RGB':\n",
    "            if cspace == 'HSV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "            elif cspace == 'LUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "            elif cspace == 'HLS':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "            elif cspace == 'YUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "            elif cspace == 'YCrCb':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "        else: feature_image = np.copy(image)   \n",
    "\n",
    "        # Call get_hog_features() with vis=False, feature_vec=True\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=False, feature_vec=True))\n",
    "            hog_features = np.ravel(hog_features)        \n",
    "        else:\n",
    "            hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                        pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "        \n",
    "        # Apply bin_spatial() to get spatial color features\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        # Apply color_hist() also with a color space option now\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins, bins_range=hist_range)\n",
    "        # Append the new feature vector to the features list\n",
    "        features.append(np.concatenate((spatial_features, hist_features,hog_features)))\n",
    "        \n",
    "    # Return list of feature vectors\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOG Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_test = mpimg.imread(car_images[35])\n",
    "car_test = cv2.cvtColor(car_test, cv2.COLOR_RGB2YCrCb)\n",
    "non_car_test = mpimg.imread(non_car_images[20])\n",
    "non_car_test = cv2.cvtColor(non_car_test, cv2.COLOR_RGB2YCrCb)\n",
    "\n",
    "imgs = []\n",
    "titles = []\n",
    "for i in range(3):\n",
    "    for feature_image, img_type in zip([car_test, non_car_test], ['Car', 'Non-car']):\n",
    "        channel = feature_image[:,:,i]\n",
    "        imgs.append(channel)\n",
    "        titles.append(img_type + ' CH%d' % i)\n",
    "        features, hog_image = get_hog_features(channel, orient=12, pix_per_cell=8, cell_per_block=2, \n",
    "                        vis=True, feature_vec=False)\n",
    "        imgs.append(hog_image)\n",
    "        titles.append(img_type + ' CH%d' % i + ' HOG')\n",
    "        \n",
    "fig, axes = plt.subplots(3, 4, sharex=True, sharey=True, figsize=(14, 10))\n",
    "axes = axes.ravel()\n",
    "for ax, img, title in zip(axes, imgs, titles):\n",
    "    ax.imshow(img, cmap='Greys_r')\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "plt.savefig('output_images/HOG_comparison.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameters\n",
    "spatial = 32\n",
    "hist_bins = 32\n",
    "colorspace = 'YCrCb' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb #YCrCb best\n",
    "orient = 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "spatial_size= (32, 32)\n",
    "heat_threshold= 4 # 12\n",
    "hog_channel = \"ALL\" # Can be 0, 1, 2, or \"ALL\" #ALL,0 best\n",
    "ystart_ystop_scale = [(405, 510, 1), (400, 600, 1.5), (500, 710, 2.5)]\n",
    "#Get a list at which each single element contains the features of the image\n",
    "car_features = extract_features(car_images, cspace=colorspace, orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_size=(spatial, spatial),\n",
    "                        hist_bins=hist_bins, hist_range=(0, 256))\n",
    "\n",
    "\n",
    "non_car_features = extract_features(non_car_images,cspace=colorspace,orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_size=(spatial, spatial),\n",
    "                        hist_bins=hist_bins, hist_range=(0, 256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preserve State to compare parameter tuning \n",
    "#Random int\n",
    "rand_state = np.random.randint(0, 100)\n",
    "\n",
    "# Create an array stack of feature vectors with rows equals to #of images and cols equal to # features\n",
    "X = np.vstack((car_features, non_car_features)).astype(np.float64)\n",
    "\n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "\n",
    "# Apply the scaler to X scale feature values for better performance\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(non_car_features))))\n",
    "\n",
    "# Split up data into randomized training and test sets,random_state is used to shuffle data before splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "print('Using spatial binning of:',spatial,'and', hist_bins,'histogram bins')\n",
    "print('Feature vector length:', len(X_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a linear SVC \n",
    "svc = LinearSVC()\n",
    "\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "\n",
    "# Prediction \n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "n_predict = 10\n",
    "print('My SVC predicts:     ', svc.predict(X_test[0:n_predict]))\n",
    "print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Saving to Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to pickle file\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"svc\"] = svc\n",
    "dist_pickle[\"scaler\"] = X_scaler\n",
    "dist_pickle[\"orient\"] = orient\n",
    "dist_pickle[\"pix_per_cell\"] = pix_per_cell\n",
    "dist_pickle[\"cell_per_block\"] = cell_per_block\n",
    "dist_pickle[\"spatial\"] = spatial\n",
    "dist_pickle[\"hist_bins\"] = hist_bins\n",
    "pickle.dump(dist_pickle, open(\"svc_pickle.p\", 'wb') )\n",
    "\n",
    "print('Classifier parameters saved to file!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading from Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading Classifier parameters...')\n",
    "dist_pickle = pickle.load( open(\"svc_pickle.p\", \"rb\" ) )\n",
    "svc = dist_pickle[\"svc\"]\n",
    "X_scaler = dist_pickle[\"scaler\"]\n",
    "orient = dist_pickle[\"orient\"]\n",
    "pix_per_cell = dist_pickle[\"pix_per_cell\"]\n",
    "cell_per_block = dist_pickle[\"cell_per_block\"]\n",
    "spatia = dist_pickle[\"spatial\"]\n",
    "hist_bins = dist_pickle[\"hist_bins\"]\n",
    "\n",
    "print('Loading is done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
